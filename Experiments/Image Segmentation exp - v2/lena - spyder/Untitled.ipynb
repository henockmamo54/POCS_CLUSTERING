{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get iris dataset from http://archive.ics.uci.edu/ml/datasets/Iris\n",
    "def load_data():\n",
    "    data = [l.strip() for l in open('iris.data') if l.strip()]\n",
    "    features = [tuple(map(float, x.split(',')[:-1])) for x in data]\n",
    "    labels = [x.split(',')[-1] for x in data]\n",
    "    return dict(zip(features, labels))\n",
    "\n",
    "def dist2(f1, f2):\n",
    "    a = np.array\n",
    "    d = a(f1)-a(f2)\n",
    "    return np.sqrt(np.dot(d, d))\n",
    "\n",
    "def mean(feats):\n",
    "    return tuple(np.mean(feats, axis=0))\n",
    "\n",
    "def assign(centers):\n",
    "    new_centers = defaultdict(list)\n",
    "    for cx in centers:\n",
    "        for x in centers[cx]:\n",
    "            best = min(centers, key=lambda c: dist2(x,c))\n",
    "            new_centers[best] += [x]\n",
    "    return new_centers\n",
    "\n",
    "def update(centers):\n",
    "    new_centers = {}\n",
    "    for c in centers:\n",
    "        new_centers[mean(centers[c])] = centers[c]\n",
    "    return new_centers\n",
    "\n",
    "def kmeans(features, k, maxiter=100):\n",
    "    centers = dict((c,[c]) for c in features[:k])\n",
    "    centers[features[k-1]] += features[k:]\n",
    "    for i in xrange(maxiter):\n",
    "        new_centers = assign(centers)\n",
    "        new_centers = update(new_centers)\n",
    "        if centers == new_centers:\n",
    "            break\n",
    "        else:\n",
    "            centers = new_centers\n",
    "    return centers\n",
    "\n",
    "def counter(alist):\n",
    "    count = defaultdict(int)\n",
    "    for x in alist:\n",
    "        count[x] += 1\n",
    "    return dict(count)\n",
    "\n",
    "def demo(seed=123):\n",
    "    \"\"\"\n",
    "    The Iris dataset used in the demo is known to have a linearly separable\n",
    "    class 'setosa' and 2 non linearly separable one each other.\n",
    "\n",
    "    >>> demo()\n",
    "    {'Iris-virginica': 1, 'Iris-versicolor': 29}\n",
    "    {'Iris-virginica': 23}\n",
    "    {'Iris-virginica': 25, 'Iris-versicolor': 21}\n",
    "    {'Iris-setosa': 48}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = load_data()\n",
    "    except IOError:\n",
    "        print \"Missing dataset! Run:\"\n",
    "        print \"wget http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "        sys.exit(1)\n",
    "    features = data.keys()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(features)\n",
    "    clusters = kmeans(features, 4)\n",
    "    for c in clusters:\n",
    "        print counter([data[x] for x in clusters[c]])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
