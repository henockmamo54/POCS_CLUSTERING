{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = plt.get_cmap('inferno')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "genres = ['alternative', 'blues', 'electronic', 'folkcountry', 'funksoulrnb',\n",
    "       'jazz', 'pop', 'raphiphop', 'rock']\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)     \n",
    "    for filename in os.listdir(f'./dataset/{g}'):\n",
    "        songname = f'./dataset/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = ['alternative', 'blues', 'electronic', 'folkcountry', 'funksoulrnb',\n",
    "       'jazz', 'pop', 'raphiphop', 'rock']\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./dataset/{g}'):\n",
    "        songname = f'./dataset/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('data.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>classical.00096.wav</td>\n",
       "      <td>0.293142</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>1932.858343</td>\n",
       "      <td>1740.355038</td>\n",
       "      <td>3573.061728</td>\n",
       "      <td>0.117520</td>\n",
       "      <td>-203.587173</td>\n",
       "      <td>111.198334</td>\n",
       "      <td>-51.526943</td>\n",
       "      <td>...</td>\n",
       "      <td>3.836547</td>\n",
       "      <td>-3.773128</td>\n",
       "      <td>5.291516</td>\n",
       "      <td>4.111487</td>\n",
       "      <td>6.639014</td>\n",
       "      <td>2.993226</td>\n",
       "      <td>3.539750</td>\n",
       "      <td>-3.361387</td>\n",
       "      <td>-3.682384</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>classical.00085.wav</td>\n",
       "      <td>0.309653</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>1525.619293</td>\n",
       "      <td>1588.175467</td>\n",
       "      <td>2732.975141</td>\n",
       "      <td>0.091588</td>\n",
       "      <td>-246.189621</td>\n",
       "      <td>149.447739</td>\n",
       "      <td>-41.977005</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.630424</td>\n",
       "      <td>-2.579881</td>\n",
       "      <td>-4.521075</td>\n",
       "      <td>-6.165346</td>\n",
       "      <td>-4.970548</td>\n",
       "      <td>-3.346554</td>\n",
       "      <td>-3.345275</td>\n",
       "      <td>-0.672826</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>hiphop.00070.wav</td>\n",
       "      <td>0.431060</td>\n",
       "      <td>0.278913</td>\n",
       "      <td>2501.271271</td>\n",
       "      <td>3049.735764</td>\n",
       "      <td>6028.546880</td>\n",
       "      <td>0.069265</td>\n",
       "      <td>-81.691071</td>\n",
       "      <td>82.321304</td>\n",
       "      <td>53.563557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.534536</td>\n",
       "      <td>-0.723483</td>\n",
       "      <td>1.349879</td>\n",
       "      <td>-0.385386</td>\n",
       "      <td>-3.133822</td>\n",
       "      <td>-0.490844</td>\n",
       "      <td>-0.732915</td>\n",
       "      <td>-3.769838</td>\n",
       "      <td>-2.506016</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>disco.00063.wav</td>\n",
       "      <td>0.547850</td>\n",
       "      <td>0.293920</td>\n",
       "      <td>2583.277699</td>\n",
       "      <td>2626.310838</td>\n",
       "      <td>5855.472926</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>-51.752674</td>\n",
       "      <td>70.331902</td>\n",
       "      <td>-3.919614</td>\n",
       "      <td>...</td>\n",
       "      <td>17.185402</td>\n",
       "      <td>-2.770966</td>\n",
       "      <td>11.966265</td>\n",
       "      <td>-1.632752</td>\n",
       "      <td>6.927689</td>\n",
       "      <td>-2.915434</td>\n",
       "      <td>4.917283</td>\n",
       "      <td>-0.487009</td>\n",
       "      <td>6.742309</td>\n",
       "      <td>disco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>jazz.00046.wav</td>\n",
       "      <td>0.250240</td>\n",
       "      <td>0.110548</td>\n",
       "      <td>1295.167919</td>\n",
       "      <td>1446.061103</td>\n",
       "      <td>2695.342035</td>\n",
       "      <td>0.058650</td>\n",
       "      <td>-204.188126</td>\n",
       "      <td>147.604614</td>\n",
       "      <td>-25.223412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.565303</td>\n",
       "      <td>1.477296</td>\n",
       "      <td>-2.724842</td>\n",
       "      <td>-0.284619</td>\n",
       "      <td>-2.217539</td>\n",
       "      <td>1.517982</td>\n",
       "      <td>-1.054650</td>\n",
       "      <td>-1.772529</td>\n",
       "      <td>-2.468120</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "196  classical.00096.wav     0.293142  0.057000        1932.858343   \n",
       "185  classical.00085.wav     0.309653  0.038889        1525.619293   \n",
       "470     hiphop.00070.wav     0.431060  0.278913        2501.271271   \n",
       "363      disco.00063.wav     0.547850  0.293920        2583.277699   \n",
       "546       jazz.00046.wav     0.250240  0.110548        1295.167919   \n",
       "\n",
       "     spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "196         1740.355038  3573.061728            0.117520 -203.587173   \n",
       "185         1588.175467  2732.975141            0.091588 -246.189621   \n",
       "470         3049.735764  6028.546880            0.069265  -81.691071   \n",
       "363         2626.310838  5855.472926            0.099773  -51.752674   \n",
       "546         1446.061103  2695.342035            0.058650 -204.188126   \n",
       "\n",
       "          mfcc2      mfcc3  ...     mfcc12    mfcc13     mfcc14    mfcc15  \\\n",
       "196  111.198334 -51.526943  ...   3.836547 -3.773128   5.291516  4.111487   \n",
       "185  149.447739 -41.977005  ...  -5.630424 -2.579881  -4.521075 -6.165346   \n",
       "470   82.321304  53.563557  ...   1.534536 -0.723483   1.349879 -0.385386   \n",
       "363   70.331902  -3.919614  ...  17.185402 -2.770966  11.966265 -1.632752   \n",
       "546  147.604614 -25.223412  ...   1.565303  1.477296  -2.724842 -0.284619   \n",
       "\n",
       "       mfcc16    mfcc17    mfcc18    mfcc19    mfcc20      label  \n",
       "196  6.639014  2.993226  3.539750 -3.361387 -3.682384  classical  \n",
       "185 -4.970548 -3.346554 -3.345275 -0.672826  0.221500  classical  \n",
       "470 -3.133822 -0.490844 -0.732915 -3.769838 -2.506016     hiphop  \n",
       "363  6.927689 -2.915434  4.917283 -0.487009  6.742309      disco  \n",
       "546 -2.217539  1.517982 -1.054650 -1.772529 -2.468120       jazz  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data=pd.read_csv('data.csv')\n",
    "data=shuffle(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "label= data.label\n",
    "x=data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(label)\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "\n",
    "# kmeans = KMeans(n_clusters=10,init='k-means++', random_state=0).fit(x)\n",
    "# kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.DataFrame()\n",
    "# test['y']=y\n",
    "# test['ny']=kmeans.labels_\n",
    "# test.head()\n",
    "# groupedtest=pd.DataFrame(test.groupby(by=['y','ny']).size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics.cluster import adjusted_rand_score\n",
    "# print(adjusted_rand_score(test.y,test.ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(xtrain,ytrain)\n",
    "pred=clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as m\n",
    "\n",
    "print(m.accuracy_score(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1101 00:25:56.912035 21224 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 0s 70us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 14.4660 - accuracy: 0.1025\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 14.4660 - accuracy: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1101 00:25:57.352209 21224 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 85us/sample - loss: 14.6675 - accuracy: 0.0900\n",
      "test_acc:  0.09\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(xtrain.shape[1],)))\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(xtrain,\n",
    "                    ytrain,\n",
    "                    epochs=20,\n",
    "                    batch_size=128)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(xtest,ytest)\n",
    "\n",
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = xtrain[:200]\n",
    "partial_x_train = xtrain[200:]\n",
    "\n",
    "y_val = ytrain[:200]\n",
    "partial_y_train = ytrain[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1101 00:25:58.410072 21224 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/30\n",
      "600/600 [==============================] - 0s 207us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 2/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 3/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 4/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 5/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 6/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 7/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 8/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 9/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 10/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 11/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 12/30\n",
      "600/600 [==============================] - 0s 18us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 13/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 14/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 15/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 16/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 17/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 18/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 19/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 20/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 21/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 22/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 23/30\n",
      "600/600 [==============================] - 0s 18us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 24/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 25/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 26/30\n",
      "600/600 [==============================] - 0s 18us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 27/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 28/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 29/30\n",
      "600/600 [==============================] - 0s 17us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n",
      "Epoch 30/30\n",
      "600/600 [==============================] - 0s 15us/sample - loss: 14.4257 - accuracy: 0.1050 - val_loss: 14.5869 - val_accuracy: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1101 00:25:59.053997 21224 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 25us/sample - loss: 14.6675 - accuracy: 0.0900\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(xtrain.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1101 00:26:46.179276 21224 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 30us/sample - loss: 14.6675 - accuracy: 0.0900\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.09\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
